# PC6 RAG from Scratch - ConstituciÃ³n EspaÃ±ola

Pipeline RAG (Retrieval Augmented Generation) construido desde cero para consultar la ConstituciÃ³n EspaÃ±ola mediante lenguaje natural.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema RAG completo que permite hacer preguntas sobre la **ConstituciÃ³n EspaÃ±ola** y obtener respuestas generadas por un LLM con contexto relevante extraÃ­do del documento oficial.

### Â¿QuÃ© es RAG?

**RAG** = Retrieval Augmented Generation (GeneraciÃ³n Aumentada por RecuperaciÃ³n)

Combina tres componentes:
- **Retrieval (RecuperaciÃ³n)**: BÃºsqueda semÃ¡ntica de informaciÃ³n relevante
- **Augmented (Aumentado)**: Enriquecimiento del prompt con contexto recuperado
- **Generation (GeneraciÃ³n)**: Respuesta generada por un LLM basada en contexto real

### Ventajas de RAG

1. **Previene alucinaciones**: El LLM genera respuestas basadas en hechos verificables del documento
2. **Datos personalizados**: Permite trabajar con documentos especÃ­ficos no presentes en el entrenamiento del LLM
3. **Trazabilidad**: Acceso a las fuentes exactas de donde proviene cada respuesta
4. **RÃ¡pido de implementar**: MÃ¡s Ã¡gil que hacer fine-tuning de un modelo

## ğŸ¯ Casos de Uso

Este tipo de sistema RAG es ideal para:
- **Chatbots de documentaciÃ³n**: Q&A sobre manuales, normativas o documentaciÃ³n tÃ©cnica
- **Asistentes legales**: Consultas sobre leyes, reglamentos y constituciones
- **AnÃ¡lisis de documentos**: ExtracciÃ³n de informaciÃ³n estructurada de documentos largos
- **Soporte educativo**: Q&A sobre libros de texto y material de estudio

## ğŸ—ï¸ Arquitectura del Pipeline

```
1. Carga de PDF â†’ 2. Procesamiento de Texto â†’ 3. Embeddings â†’ 4. BÃºsqueda Vectorial â†’ 5. GeneraciÃ³n LLM
```

### Componentes Principales

1. **Procesamiento de Documentos**
   - ExtracciÃ³n de texto del PDF (PyMuPDF)
   - Filtrado por idioma (solo castellano)
   - DivisiÃ³n en chunks semÃ¡nticos (spaCy)

2. **Embeddings**
   - Modelo: `all-mpnet-base-v2` (sentence-transformers)
   - VectorizaciÃ³n de chunks de texto
   - Almacenamiento en tensores PyTorch

3. **BÃºsqueda SemÃ¡ntica**
   - Embedding de consulta
   - BÃºsqueda por similitud de coseno (dot product)
   - RecuperaciÃ³n de top-k chunks mÃ¡s relevantes

4. **GeneraciÃ³n de Respuestas**
   - LLM: Gemma-2B-Instruct (Google/Keras)
   - Prompt engineering con contexto aumentado
   - Respuestas en espaÃ±ol basadas en artÃ­culos constitucionales

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a |
|------------|------------|
| **Entorno** | Google Colab (GPU) |
| **Procesamiento PDF** | PyMuPDF (fitz) |
| **NLP** | spaCy (`es_core_news_sm`) |
| **Embeddings** | sentence-transformers |
| **Framework DL** | PyTorch, Keras-NLP |
| **LLM** | Gemma-2B-Instruct (JAX backend) |
| **AnÃ¡lisis** | pandas, numpy |

## ğŸ“¦ InstalaciÃ³n

### Dependencias principales

```bash
pip install PyMuPDF tqdm
pip install spacy
python -m spacy download es_core_news_sm
pip install sentence-transformers
pip install -U keras-nlp keras>=3
```

### ConfiguraciÃ³n en Google Colab

```python
# Montar Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Configurar credenciales de Kaggle (para Gemma)
from google.colab import userdata
import os
os.environ["KAGGLE_USERNAME"] = userdata.get('KAGGLE_USERNAME')
os.environ["KAGGLE_KEY"] = userdata.get('KAGGLE_KEY')
```

## ğŸš€ Uso

### 1. Estructura de Datos

El documento debe estar en Google Drive:
```
/content/drive/MyDrive/data/BOE-151_Constitucion_Espanola.pdf
```

### 2. EjecuciÃ³n del Notebook

Ejecutar las celdas secuencialmente:

1. **Carga del PDF**: Monta Drive y copia el archivo localmente
2. **ExtracciÃ³n de texto**: Procesa el PDF y filtra pÃ¡ginas en castellano (0-36)
3. **Chunking**: Divide en sentencias con spaCy, agrupa en chunks de ~10 frases
4. **Embeddings**: Genera vectores con `all-mpnet-base-v2`
5. **BÃºsqueda**: Implementa funciÃ³n de recuperaciÃ³n por similitud
6. **GeneraciÃ³n**: Carga Gemma-2B y genera respuestas con contexto

### 3. Ejemplo de Consulta

```python
query = "Â¿CuÃ¡les son las funciones del Gobierno?"

# Recuperar contexto relevante
scores, indices = retrieve_relevant_resources(query, n_resources_to_return=5)

# Construir prompt aumentado
context_items = [pages_and_chunks[i]["sentence_chunk"] for i in indices]
prompt = f"""Basado en el siguiente contexto de la ConstituciÃ³n EspaÃ±ola:
{chr(10).join([f"- {item}" for item in context_items])}

Pregunta: {query}

Respuesta:"""

# Generar respuesta
response = gemma_lm.generate(prompt, max_length=256)
print(response)
```

## ğŸ“Š Procesamiento de Datos

### EstadÃ­sticas del Documento

- **PÃ¡ginas procesadas**: 37 (versiÃ³n castellano)
- **Total chunks**: ~300-400 (variable segÃºn configuraciÃ³n)
- **TamaÃ±o medio chunk**: ~200-500 caracteres
- **Tokens por chunk**: ~50-125 tokens (aprox)

### Pipeline de Chunking

```
PÃ¡ginas completas â†’ Sentencias (spaCy) â†’ AgrupaciÃ³n (10 sentencias) â†’ Filtrado (>30 tokens)
```

## ğŸ§ª ComparaciÃ³n: Sin RAG vs Con RAG

### Sin RAG (Solo conocimiento del modelo)
```
Query: "Â¿Es posible tener doble nacionalidad espaÃ±ola?"
Respuesta: "SÃ­, es posible... [respuesta genÃ©rica basada en conocimiento general]"
âš ï¸ Puede ser imprecisa o desactualizada
```

### Con RAG (Con contexto constitucional)
```
Query: "Â¿Es posible tener doble nacionalidad espaÃ±ola?"
Respuesta: "SegÃºn el ArtÃ­culo 11.3 de la ConstituciÃ³n EspaÃ±ola: 
'El Estado podrÃ¡ concertar tratados de doble nacionalidad con los paÃ­ses 
iberoamericanos o con aquellos que hayan tenido o tengan una particular 
vinculaciÃ³n con EspaÃ±a...'"
âœ… Respuesta precisa con fuente verificable
```

## ğŸ“ Estructura del Proyecto

```
PC6/
â”œâ”€â”€ PC6_rag-scratch-Constitucion.ipynb  # Notebook principal
â”œâ”€â”€ PC6_rag-scratch-Constitucion.pdf    # PDF exportado del notebook
â”œâ”€â”€ README.md                            # Este archivo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ BOE-151_Constitucion_Espanola.pdf
â”œâ”€â”€ @comands/
â”‚   â””â”€â”€ PromptDisipliando.md
â””â”€â”€ kaggle.json                          # Credenciales Kaggle (no commitear)
```

## ğŸ”‘ ConfiguraciÃ³n de Kaggle

Para usar Gemma-2B necesitas credenciales de Kaggle:

1. Ir a https://www.kaggle.com/settings/account
2. Crear un nuevo token API
3. Descargar `kaggle.json`
4. En Colab: Secrets â†’ AÃ±adir `KAGGLE_USERNAME` y `KAGGLE_KEY`

## âš™ï¸ Optimizaciones Implementadas

- **Filtrado de idioma**: Solo procesa pÃ¡ginas en castellano
- **Chunking adaptativo**: Agrupa sentencias para contexto Ã³ptimo
- **Filtrado de tokens**: Elimina chunks muy cortos (<30 tokens)
- **GPU acceleration**: Embeddings y generaciÃ³n en CUDA
- **CachÃ© local**: Copia PDF a Colab para procesamiento rÃ¡pido

## ğŸ“ Conceptos Clave Implementados

- **Embeddings semÃ¡nticos**: RepresentaciÃ³n vectorial de texto
- **Similitud de coseno**: BÃºsqueda por dot product de vectores
- **Prompt engineering**: DiseÃ±o de prompts con contexto estructurado
- **Chunking estratÃ©gico**: Balance entre contexto y granularidad
- **Text preprocessing**: Limpieza y normalizaciÃ³n de texto

## ğŸ“ Notas de Desarrollo

- El modelo spaCy puede requerir reinicio del kernel tras instalaciÃ³n
- La primera carga de Gemma-2B descarga ~5GB de pesos
- Usar backend JAX (`KERAS_BACKEND="jax"`) para mejor rendimiento
- Los chunks muy cortos se filtran para evitar ruido en bÃºsqueda
- La ConstituciÃ³n incluye 5 idiomas, solo se procesa castellano

## ğŸ¤ Contribuciones

Este proyecto es parte del **Master en AI** - PrÃ¡ctica Computacional 6 (PC6).

Para contribuir:
1. Fork del repositorio
2. Crear branch de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'AÃ±ade nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto es material educativo. El documento de la ConstituciÃ³n EspaÃ±ola es de dominio pÃºblico (BOE).

## ğŸ”— Referencias

- [ConstituciÃ³n EspaÃ±ola (BOE)](https://www.boe.es/buscar/act.php?id=BOE-A-1978-31229)
- [RAG Paper (2020)](https://arxiv.org/abs/2005.11401)
- [Sentence Transformers](https://www.sbert.net/)
- [Gemma Models (Google)](https://ai.google.dev/gemma)
- [spaCy Documentation](https://spacy.io/)

## ğŸ‘¨â€ğŸ’» Autor

Desarrollado como parte del programa de Master en Inteligencia Artificial.

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025


